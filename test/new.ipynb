{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import boto3\n",
    "from crossref.restful import Works\n",
    "\n",
    "def invoke_second_lambda(full_text_link):\n",
    "    lambda_client = boto3.client('lambda')\n",
    "    payload = {\n",
    "        'link': full_text_link\n",
    "    }\n",
    "    response = lambda_client.invoke(\n",
    "        FunctionName='second_lambda_function_name',  # Replace with your second Lambda function name\n",
    "        InvocationType='Event',\n",
    "        Payload=json.dumps(payload)\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "    api_url = base_url + \"esearch.fcgi\"\n",
    "    params = {\n",
    "        \"db\": \"pubmed\",\n",
    "        \"retmode\": \"xml\",\n",
    "        \"retmax\": 5,  # Number of papers to retrieve\n",
    "        \"term\": event['search'],  # get search from API Gateway trigger\n",
    "    }\n",
    "    \n",
    "    response = requests.get(api_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        xml_content = response.content\n",
    "        root = ET.fromstring(xml_content)\n",
    "        pubmed_ids = [id_node.text for id_node in root.findall(\".//Id\")]\n",
    "        \n",
    "        url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id={','.join(pubmed_ids)}&rettype=xml\"\n",
    "        doi_response = requests.get(url)\n",
    "        records = doi_response.content\n",
    "    \n",
    "        # Parse the XML records\n",
    "        root = ET.fromstring(records)\n",
    "    \n",
    "        # List to store dictionaries\n",
    "        pubmed_list = []\n",
    "    \n",
    "        # Find the relevant elements and extract their text\n",
    "        for pubmed_article in root.findall(\".//PubmedArticle\"):\n",
    "            # Dictionary to store the information\n",
    "            pubmed_dict = {}\n",
    "    \n",
    "            # Extract language\n",
    "            title_element = pubmed_article.find(\".//Language\")\n",
    "            language = title_element.text if title_element is not None else \"N/A\"\n",
    "            pubmed_dict[\"Language\"] = \"English\" if language == \"eng\" else \"Japanese\" if language == \"jpn\" else \"N/A\"\n",
    "    \n",
    "            # Extract title\n",
    "            title_element = pubmed_article.find(\".//ArticleTitle\")\n",
    "            pubmed_dict[\"Title\"] = title_element.text if title_element is not None else \"N/A\"\n",
    "    \n",
    "            # Extract detailed date or fallback to year\n",
    "            pub_date_element = pubmed_article.find(\".//ArticleDate\")\n",
    "            if pub_date_element is not None:\n",
    "                year_element = pub_date_element.find(\"Year\")\n",
    "                year = year_element.text if year_element is not None else \"N/A\"\n",
    "    \n",
    "                month_element = pub_date_element.find(\"Month\")\n",
    "                month = month_element.text if month_element is not None else \"N/A\"\n",
    "    \n",
    "                day_element = pub_date_element.find(\"Day\")\n",
    "                day = day_element.text if day_element is not None else \"N/A\"\n",
    "    \n",
    "                # Combine the detailed date components\n",
    "                pubmed_dict[\"Date\"] = f\"{day}/{month}/{year}\"\n",
    "            else:\n",
    "                # Fallback to year if detailed date is not available\n",
    "                year_element = pubmed_article.find(\".//PubDate/Year\")\n",
    "                pubmed_dict[\"Date\"] = year_element.text if year_element is not None else \"N/A\"\n",
    "    \n",
    "            # Extract DOI\n",
    "            doi_element = pubmed_article.find(\".//ArticleId[@IdType='doi']\")\n",
    "            if doi_element is not None:\n",
    "                pubmed_dict[\"DOI\"] = doi_element.text\n",
    "                # create object and call API for fullText link using DOI\n",
    "                works = Works()\n",
    "                textLink = works.doi(doi_element.text)\n",
    "                \n",
    "                # If there is a link to the fulltext, invoke the second Lambda function\n",
    "                if textLink is not None:\n",
    "                    pubmed_dict[\"fullText\"] = textLink['link'][0]['URL']\n",
    "                    invoke_second_lambda(pubmed_dict[\"fullText\"])\n",
    "                else:\n",
    "                    pubmed_dict[\"fullText\"] = \"N/A\"\n",
    "            else:\n",
    "                pubmed_dict[\"DOI\"] = \"N/A\"\n",
    "    \n",
    "            # Append the dictionary to the list\n",
    "            pubmed_list.append(pubmed_dict)\n",
    "    \n",
    "        # send JSON back\n",
    "        json_response = {\n",
    "            'statusCode': 200,\n",
    "            'body': {\n",
    "                'papers': pubmed_list\n",
    "            }\n",
    "        }\n",
    "    \n",
    "        return json_response\n",
    "    else:\n",
    "        return {\n",
    "            'statusCode': 500\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import textract\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    full_text_link = event['link']\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(full_text_link)\n",
    "        response.raise_for_status()\n",
    "        content_type = response.headers.get('Content-Type')\n",
    "        \n",
    "        if content_type == 'application/pdf':\n",
    "            # Extract text from the PDF\n",
    "            text = textract.process(response.content, method='pdfminer').decode('utf-8')\n",
    "            extracted_text = text.strip() if text else \"N/A\"\n",
    "        else:\n",
    "            extracted_text = \"N/A\"\n",
    "    except requests.exceptions.RequestException:\n",
    "        extracted_text = \"N/A\"\n",
    "    \n",
    "    # Return the extracted text\n",
    "    return {\n",
    "        'extractedText': extracted_text\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from crossref.restful import Works\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "    api_url = base_url + \"esearch.fcgi\"\n",
    "    params = {\n",
    "        \"db\": \"pubmed\",\n",
    "        \"retmode\": \"xml\",\n",
    "        \"retmax\": 5,  # Number of papers to retrieve\n",
    "        \"term\": event['search'],  # get search from API Gateway trigger\n",
    "    }\n",
    "    \n",
    "    response = requests.get(api_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        xml_content = response.content\n",
    "        root = ET.fromstring(xml_content)\n",
    "        pubmed_ids = [id_node.text for id_node in root.findall(\".//Id\")]\n",
    "        \n",
    "        url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id={','.join(pubmed_ids)}&rettype=xml\"\n",
    "        doi_response = requests.get(url)\n",
    "        records = doi_response.content\n",
    "    \n",
    "        # Parse the XML records\n",
    "        root = ET.fromstring(records)\n",
    "    \n",
    "        # List to store dictionaries\n",
    "        pubmed_list = []\n",
    "    \n",
    "        # Find the relevant elements and extract their text\n",
    "        for pubmed_article in root.findall(\".//PubmedArticle\"):\n",
    "            # Dictionary to store the information\n",
    "            pubmed_dict = {}\n",
    "    \n",
    "            # Extract language\n",
    "            title_element = pubmed_article.find(\".//Language\")\n",
    "            language = title_element.text if title_element is not None else \"N/A\"\n",
    "            pubmed_dict[\"Language\"] = \"English\" if language == \"eng\" else \"Japanese\" if language == \"jpn\" else \"N/A\"\n",
    "\n",
    "            \n",
    "            \n",
    "            # Extract title\n",
    "            title_element = pubmed_article.find(\".//ArticleTitle\")\n",
    "            pubmed_dict[\"Title\"] = title_element.text if title_element is not None else \"N/A\"\n",
    "    \n",
    "            # Extract detailed date or fallback to year\n",
    "            pub_date_element = pubmed_article.find(\".//ArticleDate\")\n",
    "            if pub_date_element is not None:\n",
    "                year_element = pub_date_element.find(\"Year\")\n",
    "                year = year_element.text if year_element is not None else \"N/A\"\n",
    "    \n",
    "                month_element = pub_date_element.find(\"Month\")\n",
    "                month = month_element.text if month_element is not None else \"N/A\"\n",
    "    \n",
    "                day_element = pub_date_element.find(\"Day\")\n",
    "                day = day_element.text if day_element is not None else \"N/A\"\n",
    "    \n",
    "                # Combine the detailed date components\n",
    "                pubmed_dict[\"Date\"] = f\"{day}/{month}/{year}\"\n",
    "            else:\n",
    "                # Fallback to year if detailed date is not available\n",
    "                year_element = pubmed_article.find(\".//PubDate/Year\")\n",
    "                pubmed_dict[\"Date\"] = year_element.text if year_element is not None else \"N/A\"\n",
    "    \n",
    "            # Extract DOI\n",
    "            doi_element = pubmed_article.find(\".//ArticleId[@IdType='doi']\")\n",
    "            if doi_element is not None:\n",
    "                pubmed_dict[\"DOI\"] = doi_element.text\n",
    "                # create object and call API for fullText link using DOI\n",
    "                works = Works()\n",
    "                textLink = works.doi(doi_element.text)\n",
    "                \n",
    "                # If there is not link to the fulltext, N/A\n",
    "                if textLink is not None:\n",
    "                    pubmed_dict[\"fullText\"] = textLink['link'][0]['URL']\n",
    "                else:\n",
    "                    pubmed_dict[\"fullText\"] = \"N/A\"\n",
    "                    \n",
    "            else:\n",
    "                pubmed_dict[\"DOI\"] = \"N/A\"\n",
    "            # Append the dictionary to the list\n",
    "            pubmed_list.append(pubmed_dict)\n",
    "\n",
    "        # send JSON back\n",
    "        json_response = {\n",
    "            'statusCode': 200,\n",
    "            'body': {\n",
    "                'papers': pubmed_list\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return json_response\n",
    "\n",
    "    else:\n",
    "        return {\n",
    "            'statusCode': 500\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "response = requests.get(\"https://www.mdpi.com/2075-4426/13/6/947/pdf\")\n",
    "if response.status_code == 200:\n",
    "    pdf_content = response.content\n",
    "# Specify the folder path where you want to save the PDF\n",
    "folder_path = '/temp/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# Save the PDF file\n",
    "file_path = os.path.join(folder_path, 'file.pdf')\n",
    "with open(file_path, 'wb') as file:\n",
    "    file.write(pdf_content)\n",
    "\n",
    "print('PDF file saved successfully.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
